# @package _global_
defaults:
  # Hydra's launcher API is synchronous and not async
  # https://github.com/facebookresearch/hydra/issues/1377#issuecomment-773583397 so all jobs in a batch must finish
  # before launching next batch
  - override /hydra/launcher: submitit_slurm

# Change data dir
data_dir: ${oc.env:SLURM_TMPDIR}/data

hydra:
  launcher:
    # uses job array for submitting multiple tasks under a single job, each having the below config and not sharing
    # resources between each other
    _target_: hydra_plugins.hydra_submitit_launcher.submitit_launcher.SlurmLauncher
#    timeout_min: 60
    partition: null
    python: ???
    cpus_per_task: 3          # task = process, cpus = threads if hyperthreading enabled
    gres: gpu:1               # Number of gpus for requested job. Can also specify which GPU
    nodes: 1                  # Number of nodes for job
    tasks_per_node: 1         # num of tasks to spawn in each node (will repeat each task in a job array in each node)
    mem_gb: 16                # RAM per node (not GPU memory) in GB
    array_parallelism: 15     # max num of tasks to run in parallel (via job array) with above config
    additional_parameters:
      time: 0-03:00:00                               # maximum wall time allocated for the job (D-H:MM:SS)
      mail-type: ARRAY_TASKS,FAIL,TIME_LIMIT         # events to notify user by email
      mail-user: ???                                 # email of the user

    # Change this only after you confirmed your code can handle re-submission
    # by properly resuming from the latest stored checkpoint.
    # check the following for more info on slurm_max_num_timeout
    # https://github.com/facebookincubator/submitit/blob/master/docs/checkpointing.md
    # checkpointed and requeued at most max_num_timeout times if timed out (and any number of time if preempted)
    max_num_timeout: 0

    # A list of commands to run in sbatch befure running srun
    setup: ???